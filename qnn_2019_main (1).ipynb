{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2e72471fdda4a7dab5c3b0fb62fb1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a84ba0083e44e3dabda469955121d0f",
              "IPY_MODEL_7644e8416c60424296a581cb67860851",
              "IPY_MODEL_39eb1eb091444e819ff8cb0b2a00f2b5"
            ],
            "layout": "IPY_MODEL_cbf221ec26354f7b94aaa1e39aa48f97"
          }
        },
        "3a84ba0083e44e3dabda469955121d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e1620b60174c3b8abf8535d4fd9d0b",
            "placeholder": "​",
            "style": "IPY_MODEL_af85fe4cc741497a9d07d4c55fd27d9a",
            "value": "100%"
          }
        },
        "7644e8416c60424296a581cb67860851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9df0f6820342f3a65e5b391d2f781f",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a79371d0b981469e8a7906e432f13288",
            "value": 170498071
          }
        },
        "39eb1eb091444e819ff8cb0b2a00f2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e166b204898f459bbcd426797597a2dd",
            "placeholder": "​",
            "style": "IPY_MODEL_50f9026e6b1249bd981ee4e60c248f6c",
            "value": " 170498071/170498071 [00:06&lt;00:00, 23324300.46it/s]"
          }
        },
        "cbf221ec26354f7b94aaa1e39aa48f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e1620b60174c3b8abf8535d4fd9d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af85fe4cc741497a9d07d4c55fd27d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d9df0f6820342f3a65e5b391d2f781f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79371d0b981469e8a7906e432f13288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e166b204898f459bbcd426797597a2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f9026e6b1249bd981ee4e60c248f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quaternion-Neural-Networks\n",
        "\n",
        "## Group 43\n",
        "\n",
        "\n",
        "source ([2019 code](https://github.com/heblol/Pytorch-Quaternion-Neural-Networks/blob/master/core_qnn/quaternion_layers.py)) - pytorch  \n",
        "\n",
        "source ([2018 code](https://github.com/XYZ387/QuaternionCNN_Keras/blob/master/cifar10_cnn.py)) - tensorflow\n",
        "\n",
        "<!-- @inproceedings{\n",
        "parcollet2018quaternion,\n",
        "title={Quaternion Recurrent Neural Networks},\n",
        "author={Titouan Parcollet and Mirco Ravanelli and Mohamed Morchid and Georges Linarès and Chiheb Trabelsi and Renato De Mori and Yoshua Bengio},\n",
        "booktitle={International Conference on Learning Representations},\n",
        "year={2019},\n",
        "url={https://openreview.net/forum?id=ByMHvs0cFQ},\n",
        "} -->\n",
        "\n"
      ],
      "metadata": {
        "id": "THrCEae3Acau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# pytorch-qnn v1.0\n",
        "# Titouan Parcollet\n",
        "# LIA, Université d'Avignon et des Pays du Vaucluse\n",
        "# ORKIS, Aix-en-provence\n",
        "# October 2018\n",
        "##########################################################\n",
        "\n",
        "import numpy                   as np\n",
        "from   numpy.random            import RandomState\n",
        "import torch\n",
        "from   torch.autograd           import Variable\n",
        "import torch.nn.functional      as F\n",
        "import torch.nn                 as nn\n",
        "from   torch.nn.parameter       import Parameter\n",
        "from   torch.nn                 import Module\n",
        "\n",
        "\n",
        "import math\n",
        "import sys\n",
        "\n",
        "# Imports for the quaternion_ops\n",
        "import torch.nn as nn\n",
        "from scipy.stats import chi\n",
        "import pdb"
      ],
      "metadata": {
        "id": "iHg7-Z-9AUqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import quaternion ops\n",
        "core_qnn/quaternion_ops.py\n",
        "\n",
        "I think these are helper functions."
      ],
      "metadata": {
        "id": "qTPSKwNrfsZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q_normalize(input, channel=1):\n",
        "\n",
        "    r = get_r(input)\n",
        "    i = get_i(input)\n",
        "    j = get_j(input)\n",
        "    k = get_k(input)\n",
        "\n",
        "    norm = torch.sqrt(r*r + i*i + j*j + k*k + 0.0001)\n",
        "    r = r / norm\n",
        "    i = i / norm\n",
        "    j = j / norm\n",
        "    k = k / norm\n",
        "\n",
        "    return torch.cat([r,i,j,k], dim=channel)\n",
        "\n",
        "\n",
        "def check_input(input):\n",
        "\n",
        "    if input.dim() not in {2, 3, 4, 5}:\n",
        "        raise RuntimeError(\n",
        "            \"Quaternion linear accepts only input of dimension 2 or 3. Quaternion conv accepts up to 5 dim \"\n",
        "            \" input.dim = \" + str(input.dim())\n",
        "        )\n",
        "\n",
        "    if input.dim() < 4:\n",
        "        nb_hidden = input.size()[-1]\n",
        "    else:\n",
        "        nb_hidden = input.size()[1]\n",
        "\n",
        "    if nb_hidden % 4 != 0:\n",
        "        raise RuntimeError(\n",
        "            \"Quaternion Tensors must be divisible by 4.\"\n",
        "            \" input.size()[1] = \" + str(nb_hidden)\n",
        "        )\n",
        "#\n",
        "# Getters\n",
        "#\n",
        "def get_r(input):\n",
        "    check_input(input)\n",
        "    if input.dim() < 4:\n",
        "        nb_hidden = input.size()[-1]\n",
        "    else:\n",
        "        nb_hidden = input.size()[1]\n",
        "\n",
        "    if input.dim() == 2:\n",
        "        return input.narrow(1, 0, nb_hidden // 4)\n",
        "    if input.dim() == 3:\n",
        "        return input.narrow(2, 0, nb_hidden // 4)\n",
        "    if input.dim() >= 4:\n",
        "        return input.narrow(1, 0, nb_hidden // 4)\n",
        "\n",
        "\n",
        "def get_i(input):\n",
        "    if input.dim() < 4:\n",
        "        nb_hidden = input.size()[-1]\n",
        "    else:\n",
        "        nb_hidden = input.size()[1]\n",
        "    if input.dim() == 2:\n",
        "        return input.narrow(1, nb_hidden // 4, nb_hidden // 4)\n",
        "    if input.dim() == 3:\n",
        "        return input.narrow(2, nb_hidden // 4, nb_hidden // 4)\n",
        "    if input.dim() >= 4:\n",
        "        return input.narrow(1, nb_hidden // 4, nb_hidden // 4)\n",
        "\n",
        "def get_j(input):\n",
        "    check_input(input)\n",
        "    if input.dim() < 4:\n",
        "        nb_hidden = input.size()[-1]\n",
        "    else:\n",
        "        nb_hidden = input.size()[1]\n",
        "    if input.dim() == 2:\n",
        "        return input.narrow(1, nb_hidden // 2, nb_hidden // 4)\n",
        "    if input.dim() == 3:\n",
        "        return input.narrow(2, nb_hidden // 2, nb_hidden // 4)\n",
        "    if input.dim() >= 4:\n",
        "        return input.narrow(1, nb_hidden // 2, nb_hidden // 4)\n",
        "\n",
        "def get_k(input):\n",
        "    check_input(input)\n",
        "    if input.dim() < 4:\n",
        "        nb_hidden = input.size()[-1]\n",
        "    else:\n",
        "        nb_hidden = input.size()[1]\n",
        "    if input.dim() == 2:\n",
        "        return input.narrow(1, nb_hidden - nb_hidden // 4, nb_hidden // 4)\n",
        "    if input.dim() == 3:\n",
        "        return input.narrow(2, nb_hidden - nb_hidden // 4, nb_hidden // 4)\n",
        "    if input.dim() >= 4:\n",
        "        return input.narrow(1, nb_hidden - nb_hidden // 4, nb_hidden // 4)\n",
        "\n",
        "\n",
        "def get_modulus(input, vector_form=False):\n",
        "    check_input(input)\n",
        "    r = get_r(input)\n",
        "    i = get_i(input)\n",
        "    j = get_j(input)\n",
        "    k = get_k(input)\n",
        "    if vector_form:\n",
        "        return torch.sqrt(r * r + i * i + j * j + k * k)\n",
        "    else:\n",
        "        return torch.sqrt((r * r + i * i + j * j + k * k).sum(dim=0))\n",
        "\n",
        "\n",
        "def get_normalized(input, eps=0.0001):\n",
        "    check_input(input)\n",
        "    data_modulus = get_modulus(input)\n",
        "    if input.dim() == 2:\n",
        "        data_modulus_repeated = data_modulus.repeat(1, 4)\n",
        "    elif input.dim() == 3:\n",
        "        data_modulus_repeated = data_modulus.repeat(1, 1, 4)\n",
        "    return input / (data_modulus_repeated.expand_as(input) + eps)\n",
        "\n",
        "\n",
        "def quaternion_exp(input):\n",
        "\n",
        "    r      = get_r(input)\n",
        "    i      = get_i(input)\n",
        "    j      = get_j(input)\n",
        "    k      = get_k(input)\n",
        "\n",
        "\n",
        "    norm_v = torch.sqrt(i*i+j*j+k*k) + 0.0001\n",
        "    exp    = torch.exp(r)\n",
        "\n",
        "    r      = torch.cos(norm_v)\n",
        "    i      = (i / norm_v) * torch.sin(norm_v)\n",
        "    j      = (j / norm_v) * torch.sin(norm_v)\n",
        "    k      = (k / norm_v) * torch.sin(norm_v)\n",
        "\n",
        "\n",
        "    return torch.cat([exp*r, exp*i, exp*j, exp*k], dim=1)\n",
        "\n",
        "\n",
        "def quaternion_conv(input, r_weight, i_weight, j_weight, k_weight, bias, stride,\n",
        "                    padding, groups, dilatation):\n",
        "    \"\"\"\n",
        "    Applies a quaternion convolution to the incoming data:\n",
        "    \"\"\"\n",
        "\n",
        "    cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=1)\n",
        "    cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=1)\n",
        "    cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=1)\n",
        "    cat_kernels_4_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=1)\n",
        "\n",
        "    cat_kernels_4_quaternion   = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=0)\n",
        "\n",
        "    if   input.dim() == 3:\n",
        "        convfunc = F.conv1d\n",
        "    elif input.dim() == 4:\n",
        "        convfunc = F.conv2d\n",
        "    elif input.dim() == 5:\n",
        "        convfunc = F.conv3d\n",
        "    else:\n",
        "        raise Exception(\"The convolutional input is either 3, 4 or 5 dimensions.\"\n",
        "                        \" input.dim = \" + str(input.dim()))\n",
        "\n",
        "    return convfunc(input, cat_kernels_4_quaternion, bias, stride, padding, dilatation, groups)\n",
        "\n",
        "def quaternion_transpose_conv(input, r_weight, i_weight, j_weight, k_weight, bias, stride,\n",
        "                    padding, output_padding, groups, dilatation):\n",
        "    \"\"\"\n",
        "    Applies a quaternion trasposed convolution to the incoming data:\n",
        "    \"\"\"\n",
        "\n",
        "    cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=1)\n",
        "    cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=1)\n",
        "    cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=1)\n",
        "    cat_kernels_4_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=1)\n",
        "    cat_kernels_4_quaternion   = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=0)\n",
        "\n",
        "\n",
        "    if   input.dim() == 3:\n",
        "        convfunc = F.conv_transpose1d\n",
        "    elif input.dim() == 4:\n",
        "        convfunc = F.conv_transpose2d\n",
        "    elif input.dim() == 5:\n",
        "        convfunc = F.conv_transpose3d\n",
        "    else:\n",
        "        raise Exception(\"The convolutional input is either 3, 4 or 5 dimensions.\"\n",
        "                        \" input.dim = \" + str(input.dim()))\n",
        "\n",
        "    return convfunc(input, cat_kernels_4_quaternion, bias, stride, padding, output_padding, groups, dilatation)\n",
        "\n",
        "\n",
        "def quaternion_conv_rotation(input, zero_kernel, r_weight, i_weight, j_weight, k_weight, bias, stride,\n",
        "                    padding, groups, dilatation, quaternion_format, scale=None):\n",
        "    \"\"\"\n",
        "    Applies a quaternion rotation and convolution transformation to the incoming data:\n",
        "    The rotation W*x*W^t can be replaced by R*x following:\n",
        "    https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation\n",
        "    Works for unitary and non unitary weights.\n",
        "    The initial size of the input must be a multiple of 3 if quaternion_format = False and\n",
        "    4 if quaternion_format = True.\n",
        "    \"\"\"\n",
        "\n",
        "    square_r          = (r_weight*r_weight)\n",
        "    square_i          = (i_weight*i_weight)\n",
        "    square_j          = (j_weight*j_weight)\n",
        "    square_k          = (k_weight*k_weight)\n",
        "\n",
        "    norm              = torch.sqrt(square_r+square_i+square_j+square_k + 0.0001)\n",
        "\n",
        "    #print(norm)\n",
        "\n",
        "    r_n_weight          = (r_weight / norm)\n",
        "    i_n_weight          = (i_weight / norm)\n",
        "    j_n_weight          = (j_weight / norm)\n",
        "    k_n_weight          = (k_weight / norm)\n",
        "\n",
        "    norm_factor       = 2.0\n",
        "\n",
        "    square_i          = norm_factor*(i_n_weight*i_n_weight)\n",
        "    square_j          = norm_factor*(j_n_weight*j_n_weight)\n",
        "    square_k          = norm_factor*(k_n_weight*k_n_weight)\n",
        "\n",
        "    ri                = (norm_factor*r_n_weight*i_n_weight)\n",
        "    rj                = (norm_factor*r_n_weight*j_n_weight)\n",
        "    rk                = (norm_factor*r_n_weight*k_n_weight)\n",
        "\n",
        "    ij                = (norm_factor*i_n_weight*j_n_weight)\n",
        "    ik                = (norm_factor*i_n_weight*k_n_weight)\n",
        "\n",
        "    jk                = (norm_factor*j_n_weight*k_n_weight)\n",
        "\n",
        "    if quaternion_format:\n",
        "        if scale is not None:\n",
        "            rot_kernel_1  = torch.cat([zero_kernel, scale * (1.0 - (square_j + square_k)), scale *(ij-rk), scale *(ik+rj)], dim=1)\n",
        "            rot_kernel_2  = torch.cat([zero_kernel, scale *(ij+rk), scale *(1.0 - (square_i + square_k)), scale *(jk-ri)], dim=1)\n",
        "            rot_kernel_3  = torch.cat([zero_kernel, scale *(ik-rj), scale *(jk+ri), scale *(1.0 - (square_i + square_j))], dim=1)\n",
        "        else:\n",
        "            rot_kernel_1  = torch.cat([zero_kernel, (1.0 - (square_j + square_k)), (ij-rk), (ik+rj)], dim=1)\n",
        "            rot_kernel_2  = torch.cat([zero_kernel, (ij+rk), (1.0 - (square_i + square_k)), (jk-ri)], dim=1)\n",
        "            rot_kernel_3  = torch.cat([zero_kernel, (ik-rj), (jk+ri), (1.0 - (square_i + square_j))], dim=1)\n",
        "\n",
        "        zero_kernel2  = torch.cat([zero_kernel, zero_kernel, zero_kernel, zero_kernel], dim=1)\n",
        "        global_rot_kernel = torch.cat([zero_kernel2, rot_kernel_1, rot_kernel_2, rot_kernel_3], dim=0)\n",
        "\n",
        "    else:\n",
        "        if scale is not None:\n",
        "            rot_kernel_1  = torch.cat([scale * (1.0 - (square_j + square_k)), scale *(ij-rk), scale *(ik+rj)], dim=0)\n",
        "            rot_kernel_2  = torch.cat([scale *(ij+rk), scale *(1.0 - (square_i + square_k)), scale *(jk-ri)], dim=0)\n",
        "            rot_kernel_3  = torch.cat([scale *(ik-rj), scale *(jk+ri), scale *(1.0 - (square_i + square_j))], dim=0)\n",
        "        else:\n",
        "            rot_kernel_1  = torch.cat([1.0 - (square_j + square_k), (ij-rk), (ik+rj)], dim=0)\n",
        "            rot_kernel_2  = torch.cat([(ij+rk), 1.0 - (square_i + square_k), (jk-ri)], dim=0)\n",
        "            rot_kernel_3  = torch.cat([(ik-rj), (jk+ri), (1.0 - (square_i + square_j))], dim=0)\n",
        "\n",
        "        global_rot_kernel = torch.cat([rot_kernel_1, rot_kernel_2, rot_kernel_3], dim=0)\n",
        "\n",
        "    #print(input.shape)\n",
        "    #print(square_r.shape)\n",
        "    #print(global_rot_kernel.shape)\n",
        "\n",
        "    if   input.dim() == 3:\n",
        "        convfunc = F.conv1d\n",
        "    elif input.dim() == 4:\n",
        "        convfunc = F.conv2d\n",
        "    elif input.dim() == 5:\n",
        "        convfunc = F.conv3d\n",
        "    else:\n",
        "        raise Exception(\"The convolutional input is either 3, 4 or 5 dimensions.\"\n",
        "                        \" input.dim = \" + str(input.dim()))\n",
        "\n",
        "    return convfunc(input, global_rot_kernel, bias, stride, padding, dilatation, groups)\n",
        "\n",
        "def quaternion_transpose_conv_rotation(input, zero_kernel, r_weight, i_weight, j_weight, k_weight, bias, stride,\n",
        "                    padding, output_padding, groups, dilatation, quaternion_format):\n",
        "    \"\"\"\n",
        "    Applies a quaternion rotation and transposed convolution transformation to the incoming data:\n",
        "    The rotation W*x*W^t can be replaced by R*x following:\n",
        "    https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation\n",
        "    Works for unitary and non unitary weights.\n",
        "    The initial size of the input must be a multiple of 3 if quaternion_format = False and\n",
        "    4 if quaternion_format = True.\n",
        "    \"\"\"\n",
        "\n",
        "    square_r          = (r_weight*r_weight)\n",
        "    square_i          = (i_weight*i_weight)\n",
        "    square_j          = (j_weight*j_weight)\n",
        "    square_k          = (k_weight*k_weight)\n",
        "\n",
        "    norm              = torch.sqrt(square_r+square_i+square_j+square_k + 0.0001)\n",
        "\n",
        "    r_weight          = (r_weight / norm)\n",
        "    i_weight          = (i_weight / norm)\n",
        "    j_weight          = (j_weight / norm)\n",
        "    k_weight          = (k_weight / norm)\n",
        "\n",
        "    norm_factor       = 2.0\n",
        "\n",
        "    square_i          = norm_factor*(i_weight*i_weight)\n",
        "    square_j          = norm_factor*(j_weight*j_weight)\n",
        "    square_k          = norm_factor*(k_weight*k_weight)\n",
        "\n",
        "    ri                = (norm_factor*r_weight*i_weight)\n",
        "    rj                = (norm_factor*r_weight*j_weight)\n",
        "    rk                = (norm_factor*r_weight*k_weight)\n",
        "\n",
        "    ij                = (norm_factor*i_weight*j_weight)\n",
        "    ik                = (norm_factor*i_weight*k_weight)\n",
        "\n",
        "    jk                = (norm_factor*j_weight*k_weight)\n",
        "\n",
        "    if quaternion_format:\n",
        "        rot_kernel_1  = torch.cat([zero_kernel, 1.0 - (square_j + square_k), ij-rk, ik+rj], dim=1)\n",
        "        rot_kernel_2  = torch.cat([zero_kernel, ij+rk, 1.0 - (square_i + square_k), jk-ri], dim=1)\n",
        "        rot_kernel_3  = torch.cat([zero_kernel, ik-rj, jk+ri, 1.0 - (square_i + square_j)], dim=1)\n",
        "\n",
        "        zero_kernel2  = torch.zeros(rot_kernel_1.shape).cuda()\n",
        "        global_rot_kernel = torch.cat([zero_kernel2, rot_kernel_1, rot_kernel_2, rot_kernel_3], dim=0)\n",
        "    else:\n",
        "        rot_kernel_1  = torch.cat([1.0 - (square_j + square_k), ij-rk, ik+rj], dim=1)\n",
        "        rot_kernel_2  = torch.cat([ij+rk, 1.0 - (square_i + square_k), jk-ri], dim=1)\n",
        "        rot_kernel_3  = torch.cat([ik-rj, jk+ri, 1.0 - (square_i + square_j)], dim=1)\n",
        "        global_rot_kernel = torch.cat([rot_kernel_1, rot_kernel_2, rot_kernel_3], dim=0)\n",
        "\n",
        "\n",
        "    if   input.dim() == 3:\n",
        "        convfunc = F.conv_transpose1d\n",
        "    elif input.dim() == 4:\n",
        "        convfunc = F.conv_transpose2d\n",
        "    elif input.dim() == 5:\n",
        "        convfunc = F.conv_transpose3d\n",
        "    else:\n",
        "        raise Exception(\"The convolutional input is either 3, 4 or 5 dimensions.\"\n",
        "                        \" input.dim = \" + str(input.dim()))\n",
        "\n",
        "    return convfunc(input, cat_kernels_4_quaternion, bias, stride, padding, output_padding, groups, dilatation)\n",
        "\n",
        "\n",
        "def quaternion_linear(input, r_weight, i_weight, j_weight, k_weight, bias=True):\n",
        "    \"\"\"\n",
        "    Applies a quaternion linear transformation to the incoming data:\n",
        "    It is important to notice that the forward phase of a QNN is defined\n",
        "    as W * Inputs (with * equal to the Hamilton product). The constructed\n",
        "    cat_kernels_4_quaternion is a modified version of the quaternion representation\n",
        "    so when we do torch.mm(Input,W) it's equivalent to W * Inputs.\n",
        "    \"\"\"\n",
        "\n",
        "    cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=0)\n",
        "    cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=0)\n",
        "    cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=0)\n",
        "    cat_kernels_4_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=0)\n",
        "    cat_kernels_4_quaternion   = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=1)\n",
        "\n",
        "    if input.dim() == 2 :\n",
        "\n",
        "        if bias is not None:\n",
        "            return torch.addmm(bias, input, cat_kernels_4_quaternion)\n",
        "        else:\n",
        "            return torch.mm(input, cat_kernels_4_quaternion)\n",
        "    else:\n",
        "        output = torch.matmul(input, cat_kernels_4_quaternion)\n",
        "        if bias is not None:\n",
        "            return output+bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "\n",
        "def quaternion_linear_rotation(input, zero_kernel, r_weight, i_weight, j_weight, k_weight, bias=None,\n",
        "                               quaternion_format=False, scale=None):\n",
        "    \"\"\"\n",
        "    Applies a quaternion rotation transformation to the incoming data:\n",
        "    The rotation W*x*W^t can be replaced by R*x following:\n",
        "    https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation\n",
        "    Works for unitary and non unitary weights.\n",
        "    The initial size of the input must be a multiple of 3 if quaternion_format = False and\n",
        "    4 if quaternion_format = True.\n",
        "    \"\"\"\n",
        "\n",
        "    square_r          = (r_weight*r_weight)\n",
        "    square_i          = (i_weight*i_weight)\n",
        "    square_j          = (j_weight*j_weight)\n",
        "    square_k          = (k_weight*k_weight)\n",
        "\n",
        "    norm              = torch.sqrt(square_r+square_i+square_j+square_k + 0.0001)\n",
        "\n",
        "    r_n_weight          = (r_weight / norm)\n",
        "    i_n_weight          = (i_weight / norm)\n",
        "    j_n_weight          = (j_weight / norm)\n",
        "    k_n_weight          = (k_weight / norm)\n",
        "\n",
        "    norm_factor       = 2.0\n",
        "\n",
        "    square_i          = norm_factor*(i_n_weight*i_n_weight)\n",
        "    square_j          = norm_factor*(j_n_weight*j_n_weight)\n",
        "    square_k          = norm_factor*(k_n_weight*k_n_weight)\n",
        "\n",
        "    ri                = (norm_factor*r_n_weight*i_n_weight)\n",
        "    rj                = (norm_factor*r_n_weight*j_n_weight)\n",
        "    rk                = (norm_factor*r_n_weight*k_n_weight)\n",
        "\n",
        "    ij                = (norm_factor*i_n_weight*j_n_weight)\n",
        "    ik                = (norm_factor*i_n_weight*k_n_weight)\n",
        "\n",
        "    jk                = (norm_factor*j_n_weight*k_n_weight)\n",
        "\n",
        "    if quaternion_format:\n",
        "        if scale is not None:\n",
        "            rot_kernel_1  = torch.cat([zero_kernel, scale * (1.0 - (square_j + square_k)), scale *(ij-rk), scale *(ik+rj)], dim=0)\n",
        "            rot_kernel_2  = torch.cat([zero_kernel, scale *(ij+rk), scale *(1.0 - (square_i + square_k)), scale *(jk-ri)], dim=0)\n",
        "            rot_kernel_3  = torch.cat([zero_kernel, scale *(ik-rj), scale *(jk+ri), scale *(1.0 - (square_i + square_j))], dim=0)\n",
        "        else:\n",
        "            rot_kernel_1  = torch.cat([zero_kernel, (1.0 - (square_j + square_k)), (ij-rk), (ik+rj)], dim=0)\n",
        "            rot_kernel_2  = torch.cat([zero_kernel, (ij+rk), (1.0 - (square_i + square_k)), (jk-ri)], dim=0)\n",
        "            rot_kernel_3  = torch.cat([zero_kernel, (ik-rj), (jk+ri), (1.0 - (square_i + square_j))], dim=0)\n",
        "\n",
        "        zero_kernel2  = torch.cat([zero_kernel, zero_kernel, zero_kernel, zero_kernel], dim=0)\n",
        "        global_rot_kernel = torch.cat([zero_kernel2, rot_kernel_1, rot_kernel_2, rot_kernel_3], dim=1)\n",
        "\n",
        "    else:\n",
        "        if scale is not None:\n",
        "            rot_kernel_1  = torch.cat([scale * (1.0 - (square_j + square_k)), scale *(ij-rk), scale *(ik+rj)], dim=0)\n",
        "            rot_kernel_2  = torch.cat([scale *(ij+rk), scale *(1.0 - (square_i + square_k)), scale *(jk-ri)], dim=0)\n",
        "            rot_kernel_3  = torch.cat([scale *(ik-rj), scale *(jk+ri), scale *(1.0 - (square_i + square_j))], dim=0)\n",
        "        else:\n",
        "            rot_kernel_1  = torch.cat([1.0 - (square_j + square_k), (ij-rk), (ik+rj)], dim=0)\n",
        "            rot_kernel_2  = torch.cat([(ij+rk), 1.0 - (square_i + square_k), (jk-ri)], dim=0)\n",
        "            rot_kernel_3  = torch.cat([(ik-rj), (jk+ri), (1.0 - (square_i + square_j))], dim=0)\n",
        "\n",
        "        global_rot_kernel = torch.cat([rot_kernel_1, rot_kernel_2, rot_kernel_3], dim=1)\n",
        "\n",
        "\n",
        "    if input.dim() == 2 :\n",
        "        if bias is not None:\n",
        "            return torch.addmm(bias, input, global_rot_kernel)\n",
        "        else:\n",
        "            return torch.mm(input, global_rot_kernel)\n",
        "    else:\n",
        "        output = torch.matmul(input, global_rot_kernel)\n",
        "        if bias is not None:\n",
        "            return output+bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "\n",
        "\n",
        "# Custom AUTOGRAD for lower VRAM consumption\n",
        "class QuaternionLinearFunction(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, r_weight, i_weight, j_weight, k_weight, bias=None):\n",
        "        ctx.save_for_backward(input, r_weight, i_weight, j_weight, k_weight, bias)\n",
        "        check_input(input)\n",
        "        cat_kernels_4_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=0)\n",
        "        cat_kernels_4_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=0)\n",
        "        cat_kernels_4_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=0)\n",
        "        cat_kernels_4_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=0)\n",
        "        cat_kernels_4_quaternion = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=1)\n",
        "        if input.dim() == 2 :\n",
        "            if bias is not None:\n",
        "                return torch.addmm(bias, input, cat_kernels_4_quaternion)\n",
        "            else:\n",
        "                return torch.mm(input, cat_kernels_4_quaternion)\n",
        "        else:\n",
        "            output = torch.matmul(input, cat_kernels_4_quaternion)\n",
        "            if bias is not None:\n",
        "                return output+bias\n",
        "            else:\n",
        "                return output\n",
        "\n",
        "    # This function has only a single output, so it gets only one gradient\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "\n",
        "        input, r_weight, i_weight, j_weight, k_weight, bias = ctx.saved_tensors\n",
        "        grad_input = grad_weight_r = grad_weight_i = grad_weight_j = grad_weight_k = grad_bias = None\n",
        "\n",
        "        input_r = torch.cat([r_weight, -i_weight, -j_weight, -k_weight], dim=0)\n",
        "        input_i = torch.cat([i_weight,  r_weight, -k_weight, j_weight], dim=0)\n",
        "        input_j = torch.cat([j_weight,  k_weight, r_weight, -i_weight], dim=0)\n",
        "        input_k = torch.cat([k_weight,  -j_weight, i_weight, r_weight], dim=0)\n",
        "        cat_kernels_4_quaternion_T = Variable(torch.cat([input_r, input_i, input_j, input_k], dim=1).permute(1,0), requires_grad=False)\n",
        "\n",
        "        r = get_r(input)\n",
        "        i = get_i(input)\n",
        "        j = get_j(input)\n",
        "        k = get_k(input)\n",
        "        input_r = torch.cat([r, -i, -j, -k], dim=0)\n",
        "        input_i = torch.cat([i,  r, -k, j], dim=0)\n",
        "        input_j = torch.cat([j,  k, r, -i], dim=0)\n",
        "        input_k = torch.cat([k,  -j, i, r], dim=0)\n",
        "        input_mat = Variable(torch.cat([input_r, input_i, input_j, input_k], dim=1), requires_grad=False)\n",
        "\n",
        "        r = get_r(grad_output)\n",
        "        i = get_i(grad_output)\n",
        "        j = get_j(grad_output)\n",
        "        k = get_k(grad_output)\n",
        "        input_r = torch.cat([r, i, j, k], dim=1)\n",
        "        input_i = torch.cat([-i,  r, k, -j], dim=1)\n",
        "        input_j = torch.cat([-j,  -k, r, i], dim=1)\n",
        "        input_k = torch.cat([-k,  j, -i, r], dim=1)\n",
        "        grad_mat = torch.cat([input_r, input_i, input_j, input_k], dim=0)\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            grad_input  = grad_output.mm(cat_kernels_4_quaternion_T)\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            grad_weight = grad_mat.permute(1,0).mm(input_mat).permute(1,0)\n",
        "            unit_size_x = r_weight.size(0)\n",
        "            unit_size_y = r_weight.size(1)\n",
        "            grad_weight_r = grad_weight.narrow(0,0,unit_size_x).narrow(1,0,unit_size_y)\n",
        "            grad_weight_i = grad_weight.narrow(0,0,unit_size_x).narrow(1,unit_size_y,unit_size_y)\n",
        "            grad_weight_j = grad_weight.narrow(0,0,unit_size_x).narrow(1,unit_size_y*2,unit_size_y)\n",
        "            grad_weight_k = grad_weight.narrow(0,0,unit_size_x).narrow(1,unit_size_y*3,unit_size_y)\n",
        "        if ctx.needs_input_grad[5]:\n",
        "            grad_bias   = grad_output.sum(0).squeeze(0)\n",
        "\n",
        "        return grad_input, grad_weight_r, grad_weight_i, grad_weight_j, grad_weight_k, grad_bias\n",
        "\n",
        "def hamilton_product(q0, q1):\n",
        "    \"\"\"\n",
        "    Applies a Hamilton product q0 * q1:\n",
        "    Shape:\n",
        "        - q0, q1 should be (batch_size, quaternion_number)\n",
        "        (rr' - xx' - yy' - zz')  +\n",
        "        (rx' + xr' + yz' - zy')i +\n",
        "        (ry' - xz' + yr' + zx')j +\n",
        "        (rz' + xy' - yx' + zr')k +\n",
        "    \"\"\"\n",
        "\n",
        "    q1_r = get_r(q1)\n",
        "    q1_i = get_i(q1)\n",
        "    q1_j = get_j(q1)\n",
        "    q1_k = get_k(q1)\n",
        "\n",
        "    # rr', xx', yy', and zz'\n",
        "    r_base = torch.mul(q0, q1)\n",
        "    # (rr' - xx' - yy' - zz')\n",
        "    r   = get_r(r_base) - get_i(r_base) - get_j(r_base) - get_k(r_base)\n",
        "\n",
        "    # rx', xr', yz', and zy'\n",
        "    i_base = torch.mul(q0, torch.cat([q1_i, q1_r, q1_k, q1_j], dim=1))\n",
        "    # (rx' + xr' + yz' - zy')\n",
        "    i   = get_r(i_base) + get_i(i_base) + get_j(i_base) - get_k(i_base)\n",
        "\n",
        "    # ry', xz', yr', and zx'\n",
        "    j_base = torch.mul(q0, torch.cat([q1_j, q1_k, q1_r, q1_i], dim=1))\n",
        "    # (rx' + xr' + yz' - zy')\n",
        "    j   = get_r(j_base) - get_i(j_base) + get_j(j_base) + get_k(j_base)\n",
        "\n",
        "    # rz', xy', yx', and zr'\n",
        "    k_base = torch.mul(q0, torch.cat([q1_k, q1_j, q1_i, q1_r], dim=1))\n",
        "    # (rx' + xr' + yz' - zy')\n",
        "    k   = get_r(k_base) + get_i(k_base) - get_j(k_base) + get_k(k_base)\n",
        "\n",
        "    return torch.cat([r, i, j, k], dim=1)\n",
        "\n",
        "#\n",
        "# PARAMETERS INITIALIZATION\n",
        "#\n",
        "\n",
        "def unitary_init(in_features, out_features, rng, kernel_size=None, criterion='he'):\n",
        "\n",
        "    if kernel_size is not None:\n",
        "        receptive_field = np.prod(kernel_size)\n",
        "        fan_in          = in_features  * receptive_field\n",
        "        fan_out         = out_features * receptive_field\n",
        "    else:\n",
        "        fan_in          = in_features\n",
        "        fan_out         = out_features\n",
        "\n",
        "\n",
        "    if kernel_size is None:\n",
        "        kernel_shape = (in_features, out_features)\n",
        "    else:\n",
        "        if type(kernel_size) is int:\n",
        "            kernel_shape = (out_features, in_features) + tuple((kernel_size,))\n",
        "        else:\n",
        "            kernel_shape = (out_features, in_features) + (*kernel_size,)\n",
        "\n",
        "    number_of_weights = np.prod(kernel_shape)\n",
        "    v_r = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_i = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_j = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_k = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "\n",
        "    # Unitary quaternion\n",
        "    for i in range(0, number_of_weights):\n",
        "        norm = np.sqrt(v_r[i]**2 + v_i[i]**2 + v_j[i]**2 + v_k[i]**2)+0.0001\n",
        "        v_r[i]/= norm\n",
        "        v_i[i]/= norm\n",
        "        v_j[i]/= norm\n",
        "        v_k[i]/= norm\n",
        "    v_r = v_r.reshape(kernel_shape)\n",
        "    v_i = v_i.reshape(kernel_shape)\n",
        "    v_j = v_j.reshape(kernel_shape)\n",
        "    v_k = v_k.reshape(kernel_shape)\n",
        "\n",
        "    return (v_r, v_i, v_j, v_k)\n",
        "\n",
        "def random_init(in_features, out_features, rng, kernel_size=None, criterion='glorot'):\n",
        "\n",
        "    if kernel_size is not None:\n",
        "        receptive_field = np.prod(kernel_size)\n",
        "        fan_in          = in_features  * receptive_field\n",
        "        fan_out         = out_features * receptive_field\n",
        "    else:\n",
        "        fan_in          = in_features\n",
        "        fan_out         = out_features\n",
        "\n",
        "    if criterion == 'glorot':\n",
        "        s = 1. / np.sqrt(2*(fan_in + fan_out))\n",
        "    elif criterion == 'he':\n",
        "        s = 1. / np.sqrt(2*fan_in)\n",
        "    else:\n",
        "        raise ValueError('Invalid criterion: ' + criterion)\n",
        "\n",
        "    if kernel_size is None:\n",
        "        kernel_shape = (in_features, out_features)\n",
        "    else:\n",
        "        if type(kernel_size) is int:\n",
        "            kernel_shape = (out_features, in_features) + tuple((kernel_size,))\n",
        "        else:\n",
        "            kernel_shape = (out_features, in_features) + (*kernel_size,)\n",
        "\n",
        "    number_of_weights = np.prod(kernel_shape)\n",
        "    v_r = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_i = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_j = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_k = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "\n",
        "\n",
        "\n",
        "    v_r = v_r.reshape(kernel_shape)\n",
        "    v_i = v_i.reshape(kernel_shape)\n",
        "    v_j = v_j.reshape(kernel_shape)\n",
        "    v_k = v_k.reshape(kernel_shape)\n",
        "\n",
        "    weight_r = v_r\n",
        "    weight_i = v_i\n",
        "    weight_j = v_j\n",
        "    weight_k = v_k\n",
        "    return (weight_r, weight_i, weight_j, weight_k)\n",
        "\n",
        "\n",
        "def quaternion_init(in_features, out_features, rng, kernel_size=None, criterion='glorot'):\n",
        "\n",
        "    if kernel_size is not None:\n",
        "        receptive_field = np.prod(kernel_size)\n",
        "        fan_in          = in_features  * receptive_field\n",
        "        fan_out         = out_features * receptive_field\n",
        "    else:\n",
        "        fan_in          = in_features\n",
        "        fan_out         = out_features\n",
        "\n",
        "    if criterion == 'glorot':\n",
        "        s = 1. / np.sqrt(2*(fan_in + fan_out))\n",
        "    elif criterion == 'he':\n",
        "        s = 1. / np.sqrt(2*fan_in)\n",
        "    else:\n",
        "        raise ValueError('Invalid criterion: ' + criterion)\n",
        "\n",
        "    rng = RandomState(np.random.randint(1,1234))\n",
        "\n",
        "    # Generating randoms and purely imaginary quaternions :\n",
        "    if kernel_size is None:\n",
        "        kernel_shape = (in_features, out_features)\n",
        "    else:\n",
        "        if type(kernel_size) is int:\n",
        "            kernel_shape = (out_features, in_features) + tuple((kernel_size,))\n",
        "        else:\n",
        "            kernel_shape = (out_features, in_features) + (*kernel_size,)\n",
        "\n",
        "    modulus = chi.rvs(4,loc=0,scale=s,size=kernel_shape)\n",
        "    number_of_weights = np.prod(kernel_shape)\n",
        "    v_i = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_j = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "    v_k = np.random.uniform(-1.0,1.0,number_of_weights)\n",
        "\n",
        "    # Purely imaginary quaternions unitary\n",
        "    for i in range(0, number_of_weights):\n",
        "        norm = np.sqrt(v_i[i]**2 + v_j[i]**2 + v_k[i]**2 +0.0001)\n",
        "        v_i[i]/= norm\n",
        "        v_j[i]/= norm\n",
        "        v_k[i]/= norm\n",
        "    v_i = v_i.reshape(kernel_shape)\n",
        "    v_j = v_j.reshape(kernel_shape)\n",
        "    v_k = v_k.reshape(kernel_shape)\n",
        "\n",
        "    phase = rng.uniform(low=-np.pi, high=np.pi, size=kernel_shape)\n",
        "\n",
        "    weight_r = modulus * np.cos(phase)\n",
        "    weight_i = modulus * v_i*np.sin(phase)\n",
        "    weight_j = modulus * v_j*np.sin(phase)\n",
        "    weight_k = modulus * v_k*np.sin(phase)\n",
        "\n",
        "    return (weight_r, weight_i, weight_j, weight_k)\n",
        "\n",
        "def create_dropout_mask(dropout_p, size, rng, as_type, operation='linear'):\n",
        "    if operation == 'linear':\n",
        "        mask = rng.binomial(n=1, p=1-dropout_p, size=size)\n",
        "        return Variable(torch.from_numpy(mask).type(as_type))\n",
        "    else:\n",
        "         raise Exception(\"create_dropout_mask accepts only 'linear'. Found operation = \"\n",
        "                        + str(operation))\n",
        "\n",
        "def affect_init(r_weight, i_weight, j_weight, k_weight, init_func, rng, init_criterion):\n",
        "    if r_weight.size() != i_weight.size() or r_weight.size() != j_weight.size() or \\\n",
        "    r_weight.size() != k_weight.size() :\n",
        "         raise ValueError('The real and imaginary weights '\n",
        "                 'should have the same size . Found: r:'\n",
        "                 + str(r_weight.size()) +' i:'\n",
        "                 + str(i_weight.size()) +' j:'\n",
        "                 + str(j_weight.size()) +' k:'\n",
        "                 + str(k_weight.size()))\n",
        "\n",
        "    elif r_weight.dim() != 2:\n",
        "        raise Exception('affect_init accepts only matrices. Found dimension = '\n",
        "                        + str(r_weight.dim()))\n",
        "    kernel_size = None\n",
        "    r, i, j, k  = init_func(r_weight.size(0), r_weight.size(1), rng, kernel_size, init_criterion)\n",
        "    r, i, j, k  = torch.from_numpy(r), torch.from_numpy(i), torch.from_numpy(j), torch.from_numpy(k)\n",
        "    r_weight.data = r.type_as(r_weight.data)\n",
        "    i_weight.data = i.type_as(i_weight.data)\n",
        "    j_weight.data = j.type_as(j_weight.data)\n",
        "    k_weight.data = k.type_as(k_weight.data)\n",
        "\n",
        "\n",
        "def affect_init_conv(r_weight, i_weight, j_weight, k_weight, kernel_size, init_func, rng,\n",
        "                     init_criterion):\n",
        "    if r_weight.size() != i_weight.size() or r_weight.size() != j_weight.size() or \\\n",
        "    r_weight.size() != k_weight.size() :\n",
        "         raise ValueError('The real and imaginary weights '\n",
        "                 'should have the same size . Found: r:'\n",
        "                 + str(r_weight.size()) +' i:'\n",
        "                 + str(i_weight.size()) +' j:'\n",
        "                 + str(j_weight.size()) +' k:'\n",
        "                 + str(k_weight.size()))\n",
        "\n",
        "    elif 2 >= r_weight.dim():\n",
        "        raise Exception('affect_conv_init accepts only tensors that have more than 2 dimensions. Found dimension = '\n",
        "                        + str(real_weight.dim()))\n",
        "\n",
        "    r, i, j, k = init_func(\n",
        "        r_weight.size(1),\n",
        "        r_weight.size(0),\n",
        "        rng=rng,\n",
        "        kernel_size=kernel_size,\n",
        "        criterion=init_criterion\n",
        "    )\n",
        "    r, i, j, k = torch.from_numpy(r), torch.from_numpy(i), torch.from_numpy(j), torch.from_numpy(k)\n",
        "    r_weight.data = r.type_as(r_weight.data)\n",
        "    i_weight.data = i.type_as(i_weight.data)\n",
        "    j_weight.data = j.type_as(j_weight.data)\n",
        "    k_weight.data = k.type_as(k_weight.data)\n",
        "\n",
        "def get_kernel_and_weight_shape(operation, in_channels, out_channels, kernel_size):\n",
        "    if operation == 'convolution1d':\n",
        "        if type(kernel_size) is not int:\n",
        "            raise ValueError(\n",
        "                \"\"\"An invalid kernel_size was supplied for a 1d convolution. The kernel size\n",
        "                must be integer in the case. Found kernel_size = \"\"\" + str(kernel_size)\n",
        "            )\n",
        "        else:\n",
        "            ks = kernel_size\n",
        "            w_shape = (out_channels, in_channels) + tuple((ks,))\n",
        "    else:# in case it is 2d or 3d.\n",
        "        if   operation == 'convolution2d' and type(kernel_size) is int:\n",
        "            ks = (kernel_size, kernel_size)\n",
        "        elif operation == 'convolution3d' and type(kernel_size) is int:\n",
        "            ks = (kernel_size, kernel_size, kernel_size)\n",
        "        elif type(kernel_size) is not int:\n",
        "            if   operation == 'convolution2d' and len(kernel_size) != 2:\n",
        "                raise ValueError(\n",
        "                    \"\"\"An invalid kernel_size was supplied for a 2d convolution. The kernel size\n",
        "                    must be either an integer or a tuple of 2. Found kernel_size = \"\"\" + str(kernel_size)\n",
        "                )\n",
        "            elif operation == 'convolution3d' and len(kernel_size) != 3:\n",
        "                raise ValueError(\n",
        "                    \"\"\"An invalid kernel_size was supplied for a 3d convolution. The kernel size\n",
        "                    must be either an integer or a tuple of 3. Found kernel_size = \"\"\" + str(kernel_size)\n",
        "                )\n",
        "            else:\n",
        "                ks = kernel_size\n",
        "        w_shape = (out_channels, in_channels) + (*ks,)\n",
        "    return ks, w_shape"
      ],
      "metadata": {
        "id": "sjNMdWdnfryn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the quaternion layers\n",
        "core_qnn/quaternion_layers.py\n"
      ],
      "metadata": {
        "id": "ST8EI9T-dRme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuaternionTransposeConv(Module):\n",
        "    r\"\"\"Applies a Quaternion Transposed Convolution (or Deconvolution) to the incoming data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 dilatation=1, padding=0, output_padding=0, groups=1, bias=True, init_criterion='he',\n",
        "                 weight_init='quaternion', seed=None, operation='convolution2d', rotation=False,\n",
        "                 quaternion_format=False):\n",
        "\n",
        "        super(QuaternionTransposeConv, self).__init__()\n",
        "\n",
        "        self.in_channels       = in_channels  // 4\n",
        "        self.out_channels      = out_channels // 4\n",
        "        self.stride            = stride\n",
        "        self.padding           = padding\n",
        "        self.output_padding    = output_padding\n",
        "        self.groups            = groups\n",
        "        self.dilatation        = dilatation\n",
        "        self.init_criterion    = init_criterion\n",
        "        self.weight_init       = weight_init\n",
        "        self.seed              = seed if seed is not None else np.random.randint(0,1234)\n",
        "        self.rng               = RandomState(self.seed)\n",
        "        self.operation         = operation\n",
        "        self.rotation          = rotation\n",
        "        self.quaternion_format = quaternion_format\n",
        "        self.winit             = {'quaternion': quaternion_init,\n",
        "                                  'unitary'   : unitary_init,\n",
        "                                  'random'    : random_init}[self.weight_init]\n",
        "\n",
        "\n",
        "        (self.kernel_size, self.w_shape) = get_kernel_and_weight_shape( self.operation,\n",
        "            self.out_channels, self.in_channels, kernel_size )\n",
        "\n",
        "        self.r_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.i_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.j_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.k_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        affect_init_conv(self.r_weight, self.i_weight, self.j_weight, self.k_weight,\n",
        "                    self.kernel_size, self.winit, self.rng, self.init_criterion)\n",
        "        if self.bias is not None:\n",
        "           self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if self.rotation:\n",
        "            return quaternion_tranpose_conv_rotation(input, self.r_weight, self.i_weight,\n",
        "                self.j_weight, self.k_weight, self.bias, self.stride, self.padding,\n",
        "                self.output_padding, self.groups, self.dilatation, self.quaternion_format)\n",
        "        else:\n",
        "            return quaternion_transpose_conv(input, self.r_weight, self.i_weight, self.j_weight,\n",
        "                self.k_weight, self.bias, self.stride, self.padding, self.output_padding,\n",
        "                self.groups, self.dilatation)\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_channels='      + str(self.in_channels) \\\n",
        "            + ', out_channels='   + str(self.out_channels) \\\n",
        "            + ', bias='           + str(self.bias is not None) \\\n",
        "            + ', kernel_size='    + str(self.kernel_size) \\\n",
        "            + ', stride='         + str(self.stride) \\\n",
        "            + ', padding='        + str(self.padding) \\\n",
        "            + ', dilation='       + str(self.dilation) \\\n",
        "            + ', init_criterion=' + str(self.init_criterion) \\\n",
        "            + ', weight_init='    + str(self.weight_init) \\\n",
        "            + ', seed='           + str(self.seed) \\\n",
        "            + ', operation='      + str(self.operation) + ')'"
      ],
      "metadata": {
        "id": "DEloN1wpdFm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuaternionConv(Module):\n",
        "    r\"\"\"Applies a Quaternion Convolution to the incoming data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 dilatation=1, padding=0, groups=1, bias=True, init_criterion='glorot',\n",
        "                 weight_init='quaternion', seed=None, operation='convolution2d', rotation=False, quaternion_format=True, scale=False):\n",
        "\n",
        "        super(QuaternionConv, self).__init__()\n",
        "\n",
        "        self.in_channels       = in_channels  // 4\n",
        "        self.out_channels      = out_channels // 4\n",
        "        self.stride            = stride\n",
        "        self.padding           = padding\n",
        "        self.groups            = groups\n",
        "        self.dilatation        = dilatation\n",
        "        self.init_criterion    = init_criterion\n",
        "        self.weight_init       = weight_init\n",
        "        self.seed              = seed if seed is not None else np.random.randint(0,1234)\n",
        "        self.rng               = RandomState(self.seed)\n",
        "        self.operation         = operation\n",
        "        self.rotation          = rotation\n",
        "        self.quaternion_format = quaternion_format\n",
        "        self.winit             =    {'quaternion': quaternion_init,\n",
        "                                     'unitary'   : unitary_init,\n",
        "                                     'random'    : random_init}[self.weight_init]\n",
        "        self.scale             = scale\n",
        "\n",
        "\n",
        "        (self.kernel_size, self.w_shape) = get_kernel_and_weight_shape( self.operation,\n",
        "            self.in_channels, self.out_channels, kernel_size )\n",
        "\n",
        "        self.r_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.i_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.j_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "        self.k_weight  = Parameter(torch.Tensor(*self.w_shape))\n",
        "\n",
        "        if self.scale:\n",
        "            self.scale_param  = Parameter(torch.Tensor(self.r_weight.shape))\n",
        "        else:\n",
        "            self.scale_param  = None\n",
        "\n",
        "        if self.rotation:\n",
        "            self.zero_kernel = Parameter(torch.zeros(self.r_weight.shape), requires_grad=False)\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        affect_init_conv(self.r_weight, self.i_weight, self.j_weight, self.k_weight,\n",
        "                    self.kernel_size, self.winit, self.rng, self.init_criterion)\n",
        "        if self.scale_param is not None:\n",
        "            torch.nn.init.xavier_uniform_(self.scale_param.data)\n",
        "        if self.bias is not None:\n",
        "           self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "\n",
        "        if self.rotation:\n",
        "            return quaternion_conv_rotation(input, self.zero_kernel, self.r_weight, self.i_weight, self.j_weight,\n",
        "                self.k_weight, self.bias, self.stride, self.padding, self.groups, self.dilatation,\n",
        "                self.quaternion_format, self.scale_param)\n",
        "        else:\n",
        "            return quaternion_conv(input, self.r_weight, self.i_weight, self.j_weight,\n",
        "                self.k_weight, self.bias, self.stride, self.padding, self.groups, self.dilatation)\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_channels='      + str(self.in_channels) \\\n",
        "            + ', out_channels='   + str(self.out_channels) \\\n",
        "            + ', bias='           + str(self.bias is not None) \\\n",
        "            + ', kernel_size='    + str(self.kernel_size) \\\n",
        "            + ', stride='         + str(self.stride) \\\n",
        "            + ', padding='        + str(self.padding) \\\n",
        "            + ', init_criterion=' + str(self.init_criterion) \\\n",
        "            + ', weight_init='    + str(self.weight_init) \\\n",
        "            + ', seed='           + str(self.seed) \\\n",
        "            + ', rotation='       + str(self.rotation) \\\n",
        "            + ', q_format='       + str(self.quaternion_format) \\\n",
        "            + ', operation='      + str(self.operation) + ')'"
      ],
      "metadata": {
        "id": "vig8w0BgdJuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuaternionLinearAutograd(Module):\n",
        "    r\"\"\"Applies a quaternion linear transformation to the incoming data. A custom\n",
        "    Autograd function is call to drastically reduce the VRAM consumption. Nonetheless, computing\n",
        "    time is also slower compared to QuaternionLinear().\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 init_criterion='glorot', weight_init='quaternion',\n",
        "                 seed=None, rotation=False, quaternion_format=True, scale=False):\n",
        "\n",
        "        super(QuaternionLinearAutograd, self).__init__()\n",
        "        self.in_features       = in_features//4\n",
        "        self.out_features      = out_features//4\n",
        "        self.rotation          = rotation\n",
        "        self.quaternion_format = quaternion_format\n",
        "        self.r_weight = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.i_weight = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.j_weight = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.k_weight = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.scale    = scale\n",
        "\n",
        "        if self.scale:\n",
        "            self.scale_param  = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        else:\n",
        "            self.scale_param  = None\n",
        "\n",
        "        if self.rotation:\n",
        "            self.zero_kernel  = Parameter(torch.zeros(self.r_weight.shape), requires_grad=False)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(self.out_features*4))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.init_criterion = init_criterion\n",
        "        self.weight_init = weight_init\n",
        "        self.seed = seed if seed is not None else np.random.randint(0,1234)\n",
        "        self.rng = RandomState(self.seed)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        winit = {'quaternion': quaternion_init, 'unitary': unitary_init, 'random': random_init}[self.weight_init]\n",
        "        if self.scale_param is not None:\n",
        "            torch.nn.init.xavier_uniform_(self.scale_param.data)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.fill_(0)\n",
        "        affect_init(self.r_weight, self.i_weight, self.j_weight, self.k_weight, winit,\n",
        "                    self.rng, self.init_criterion)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # See the autograd section for explanation of what happens here.\n",
        "        if self.rotation:\n",
        "            return quaternion_linear_rotation(input, self.zero_kernel, self.r_weight, self.i_weight, self.j_weight, self.k_weight, self.bias, self.quaternion_format, self.scale_param)\n",
        "        else:\n",
        "            return quaternion_linear(input, self.r_weight, self.i_weight, self.j_weight, self.k_weight, self.bias)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_features=' + str(self.in_features) \\\n",
        "            + ', out_features=' + str(self.out_features) \\\n",
        "            + ', bias=' + str(self.bias is not None) \\\n",
        "            + ', init_criterion=' + str(self.init_criterion) \\\n",
        "            + ', weight_init=' + str(self.weight_init) \\\n",
        "            + ', rotation='       + str(self.rotation) \\\n",
        "            + ', seed=' + str(self.seed) + ')'"
      ],
      "metadata": {
        "id": "EpTeIdM2dNiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuaternionLinear(Module):\n",
        "    r\"\"\"Applies a quaternion linear transformation to the incoming data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 init_criterion='he', weight_init='quaternion',\n",
        "                 seed=None):\n",
        "\n",
        "        super(QuaternionLinear, self).__init__()\n",
        "        self.in_features  = in_features//4\n",
        "        self.out_features = out_features//4\n",
        "        self.r_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.i_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.j_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "        self.k_weight     = Parameter(torch.Tensor(self.in_features, self.out_features))\n",
        "\n",
        "        if bias:\n",
        "            self.bias     = Parameter(torch.Tensor(self.out_features*4))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.init_criterion = init_criterion\n",
        "        self.weight_init    = weight_init\n",
        "        self.seed           = seed if seed is not None else np.random.randint(0,1234)\n",
        "        self.rng            = RandomState(self.seed)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        winit = {'quaternion': quaternion_init,\n",
        "                 'unitary': unitary_init}[self.weight_init]\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.fill_(0)\n",
        "        affect_init(self.r_weight, self.i_weight, self.j_weight, self.k_weight, winit,\n",
        "                    self.rng, self.init_criterion)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # See the autograd section for explanation of what happens here.\n",
        "        if input.dim() == 3:\n",
        "            T, N, C = input.size()\n",
        "            input  = input.view(T * N, C)\n",
        "            output = QuaternionLinearFunction.apply(input, self.r_weight, self.i_weight, self.j_weight, self.k_weight, self.bias)\n",
        "            output = output.view(T, N, output.size(1))\n",
        "        elif input.dim() == 2:\n",
        "            output = QuaternionLinearFunction.apply(input, self.r_weight, self.i_weight, self.j_weight, self.k_weight, self.bias)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'in_features=' + str(self.in_features) \\\n",
        "            + ', out_features=' + str(self.out_features) \\\n",
        "            + ', bias=' + str(self.bias is not None) \\\n",
        "            + ', init_criterion=' + str(self.init_criterion) \\\n",
        "            + ', weight_init=' + str(self.weight_init) \\\n",
        "            + ', seed=' + str(self.seed) + ')'"
      ],
      "metadata": {
        "id": "E8D6OEFGdPnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reimplementation\n",
        "## Import required packages"
      ],
      "metadata": {
        "id": "47cABIb1orZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages to import Cifar\n",
        "from torchvision.datasets import CIFAR10\n",
        "# from torchvision.transforms import ToTensor\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "JfQ78J9ZrG3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import CIFAR"
      ],
      "metadata": {
        "id": "nZLGsmNS6RtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Cifar10\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def convert_to_quaternion(batch):\n",
        "  new_batch = torch.empty(len(batch), 4, 32, 32)\n",
        "  labels = torch.LongTensor(len(batch))\n",
        "\n",
        "  # Transform images to quaternion matrices\n",
        "  for i in range(len(batch)):\n",
        "    image, label = batch[i][0], batch[i][1]\n",
        "    real = torch.zeros(32, 32)\n",
        "    new_image = torch.cat((image, real.unsqueeze(0)), dim=0)\n",
        "    new_batch[i, :, :, :] = new_image\n",
        "    labels[i] = label\n",
        "\n",
        "  return new_batch, labels\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomAffine(degrees = 0, translate = (0.1, 0.1)),\n",
        "    transforms.RandomHorizontalFlip(0.5)\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='data/', download=True, transform=transform)\n",
        "test_dataset = CIFAR10(root='data/', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "torch.manual_seed(43)\n",
        "val_size = 0\n",
        "train_size = len(train_dataset) - val_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "##############################################################################\n",
        "# These values are directly copied from the Keras tensorflow implementation. #\n",
        "##############################################################################\n",
        "batch_size = 32\n",
        "\n",
        "num_predictions = 20\n",
        "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model_Q_REIMPLEMENTATION.h5'\n",
        "\n",
        "# TODO:\n",
        "# - they split the data into categorical data. Do we have to do this too?\n",
        "# - Transfor data in pytorch, equaivilant of the data_agumentation in Tensorflow.\n",
        "\n",
        "##############################################################################\n",
        "# END END                                                                    #\n",
        "##############################################################################\n",
        "\n",
        "quaternion = False\n",
        "if quaternion:\n",
        "  train_loader = DataLoader(train_dataset, batch_size, shuffle=True, \n",
        "                          collate_fn=convert_to_quaternion)\n",
        "  test_loader = DataLoader(test_dataset, batch_size*2, num_workers=2, \n",
        "                         pin_memory=True, collate_fn=convert_to_quaternion)\n",
        "else:\n",
        "  train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size*2, num_workers=2, \n",
        "                         pin_memory=True)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "e2e72471fdda4a7dab5c3b0fb62fb1a3",
            "3a84ba0083e44e3dabda469955121d0f",
            "7644e8416c60424296a581cb67860851",
            "39eb1eb091444e819ff8cb0b2a00f2b5",
            "cbf221ec26354f7b94aaa1e39aa48f97",
            "52e1620b60174c3b8abf8535d4fd9d0b",
            "af85fe4cc741497a9d07d4c55fd27d9a",
            "6d9df0f6820342f3a65e5b391d2f781f",
            "a79371d0b981469e8a7906e432f13288",
            "e166b204898f459bbcd426797597a2dd",
            "50f9026e6b1249bd981ee4e60c248f6c"
          ]
        },
        "id": "WOyuqd8VompS",
        "outputId": "ec313b75-4f68-40b7-9eac-77b25d181fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2e72471fdda4a7dab5c3b0fb62fb1a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpY_B-OK3xXY",
        "outputId": "7e35af8e-7083-48d0-fa6a-cc602d07bc25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu():\n",
        "    \"\"\"\n",
        "    If GPU is available, return torch.device as cuda:0; else return torch.device\n",
        "    as cpu.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "      print(\"Training on GPU\")\n",
        "      device = torch.device('cuda:0')\n",
        "    else:\n",
        "      print(\"Training on CPU\")\n",
        "      device = torch.device('cpu')\n",
        "    return device"
      ],
      "metadata": {
        "id": "Cnu54RHkFUae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement baseline \n",
        "referred in the paper as \"real-valued CNN\""
      ],
      "metadata": {
        "id": "3Qwh2dFIrONV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    3-layer CNN network with max pooling\n",
        "    \n",
        "    Args:\n",
        "        in_channels: number of features of the input image (\"depth of image\")\n",
        "        hidden_channels: number of hidden features (\"depth of convolved images\")\n",
        "        out_features: number of features in output layer\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels: int, hidden_channels, out_features: int, kernel_size: int):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "          # block 1\n",
        "          nn.Conv2d(in_channels, hidden_channels[0], kernel_size, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(hidden_channels[0], hidden_channels[1], kernel_size),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, stride=2),\n",
        "          torch.nn.Dropout(p=0.25),\n",
        "\n",
        "          # block 2\n",
        "          nn.Conv2d(hidden_channels[1], hidden_channels[2], kernel_size, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(hidden_channels[2], hidden_channels[3], kernel_size),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, stride=2),\n",
        "          torch.nn.Dropout(p=0.25),\n",
        "\n",
        "          # block 3\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(2304, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.Linear(512, out_features),\n",
        "          nn.Softmax()\n",
        "        )\n",
        "    \n",
        "    def accuracy(self, outputs, labels):\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "    def training_step(self, batch):\n",
        "      images, labels = batch\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      out = self(images)                  # Generate predictions\n",
        "      loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "      accu = self.accuracy(out,labels)\n",
        "\n",
        "      return loss, accu\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = self.accuracy(out, labels)           # Calculate accuracy\n",
        "\n",
        "        return loss.detach(), acc\n",
        "    \n",
        "    def epoch_end(self, epoch, train_acc, train_loss, test_acc, test_loss):\n",
        "        print(\"Epoch :\",epoch + 1)\n",
        "        print(f'Train Accuracy:{train_acc*100:.2f}% Validation Accuracy:{test_acc*100:.2f}%')\n",
        "        print(f'Train Loss:{train_loss:.4f} Validation Loss:{test_loss:.4f}')\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.net.forward(x)\n",
        "      \n"
      ],
      "metadata": {
        "id": "3dnAyWlOmJR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement QNN"
      ],
      "metadata": {
        "id": "A9YpyaJa9Shj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_features, kernel_size = 3):\n",
        "        super(QNN, self).__init__()\n",
        "    \n",
        "        self.net = nn.Sequential(\n",
        "            # Padding\n",
        "            QuaternionConv(in_channels, hidden_channels[0], \n",
        "                                     kernel_size, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            QuaternionConv(hidden_channels[0], hidden_channels[1],\n",
        "                              kernel_size, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            torch.nn.Dropout(p=0.25),\n",
        "\n",
        "            QuaternionConv(hidden_channels[1], hidden_channels[2],\n",
        "                              kernel_size, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            QuaternionConv(hidden_channels[2], hidden_channels[3],\n",
        "                              kernel_size, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            torch.nn.Dropout(p=0.25),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            # QDense\n",
        "            QuaternionLinear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            # Dense\n",
        "            nn.Linear(512, out_features),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "    \n",
        "    def accuracy(self, outputs, labels):\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "    def training_step(self, batch):\n",
        "      images, labels = batch\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      out = self(images)                  # Generate predictions\n",
        "      loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "      accu = self.accuracy(out, labels)\n",
        "\n",
        "      return loss, accu\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = self.accuracy(out, labels)           # Calculate accuracy\n",
        "\n",
        "        return loss.detach(), acc\n",
        "    \n",
        "    def epoch_end(self, epoch, train_acc, train_loss, test_acc, test_loss):\n",
        "        print(\"Epoch :\",epoch + 1)\n",
        "        print(f'Train Accuracy:{train_acc*100:.2f}% Validation Accuracy:{test_acc*100:.2f}%')\n",
        "        print(f'Train Loss:{train_loss:.4f} Validation Loss:{test_loss:.4f}')\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.net.forward(x)"
      ],
      "metadata": {
        "id": "0LFih37j9Yin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "if quaternion:\n",
        "  in_channels = 4\n",
        "  hidden_channels = [32, 32, 64, 64]\n",
        "  out_features = 10\n",
        "\n",
        "  net = QNN(in_channels, hidden_channels, out_features)\n",
        "else:\n",
        "  in_channels = 3\n",
        "  hidden_channels = [32, 32, 64, 64]\n",
        "  out_features = 10\n",
        "\n",
        "  net = CNN(in_channels, hidden_channels, out_features, kernel_size=3)\n",
        "  # summary(net, (3, 32, 32))\n",
        "\n",
        "epochs = 80\n",
        "lr=0.0001\n",
        "decay=1e-6\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
      ],
      "metadata": {
        "id": "bVfEfc079b62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "93IZgCMq8avy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "\n",
        "running_loss = 0\n",
        "train_losses = []\n",
        "train_accuracy = []\n",
        "test_accs = []\n",
        "\n",
        "# learning rate decay\n",
        "# weight initialization\n",
        "\n",
        "device = try_gpu()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    batch_losses = []\n",
        "    batch_acc = []\n",
        "    for batch in data_loader:\n",
        "      loss, acc = model.validation_step(batch)\n",
        "      batch_losses.append(loss.item())\n",
        "      batch_acc.append(acc.item())\n",
        "    return mean(batch_losses), mean(batch_acc)\n",
        "\n",
        "best_valid = None\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch \" + str(epoch))\n",
        "\n",
        "    # Network in training mode and to device\n",
        "    net.train()\n",
        "    net.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for batch in tqdm(train_loader):\n",
        "        loss, accu = net.training_step(batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.cpu().item()\n",
        "\n",
        "    # Validation\n",
        "    test_loss, test_acc = evaluate(net, test_loader)\n",
        "    train_loss, train_acc = evaluate(net, train_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Learning rate decay\n",
        "    # scheduler.step()\n",
        "\n",
        "    net.epoch_end(epoch, train_acc, train_loss, test_acc, test_loss)\n",
        "    if (best_valid == None or best_valid < test_acc):\n",
        "        best_valid = test_acc\n",
        "        torch.save(net.state_dict(), 'cifar10-cnn.pth')\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x89xT1MF4wjh",
        "outputId": "4bbf182b-22ef-4a2d-a1a4-06b30d9dc6be",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU\n",
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1563 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            "100%|██████████| 1563/1563 [00:50<00:00, 30.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "Train Accuracy:28.99% Validation Accuracy:30.18%\n",
            "Train Loss:2.1557 Validation Loss:2.1422\n",
            "\n",
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 2\n",
            "Train Accuracy:34.52% Validation Accuracy:36.63%\n",
            "Train Loss:2.1082 Validation Loss:2.0905\n",
            "\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 3\n",
            "Train Accuracy:36.64% Validation Accuracy:39.50%\n",
            "Train Loss:2.0864 Validation Loss:2.0631\n",
            "\n",
            "\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 4\n",
            "Train Accuracy:38.58% Validation Accuracy:40.47%\n",
            "Train Loss:2.0668 Validation Loss:2.0478\n",
            "\n",
            "\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 5\n",
            "Train Accuracy:41.06% Validation Accuracy:42.88%\n",
            "Train Loss:2.0441 Validation Loss:2.0232\n",
            "\n",
            "\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 6\n",
            "Train Accuracy:42.46% Validation Accuracy:43.46%\n",
            "Train Loss:2.0315 Validation Loss:2.0194\n",
            "\n",
            "\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:46<00:00, 33.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 7\n",
            "Train Accuracy:44.51% Validation Accuracy:45.82%\n",
            "Train Loss:2.0121 Validation Loss:1.9993\n",
            "\n",
            "\n",
            "Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 8\n",
            "Train Accuracy:45.70% Validation Accuracy:47.23%\n",
            "Train Loss:2.0003 Validation Loss:1.9860\n",
            "\n",
            "\n",
            "Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 9\n",
            "Train Accuracy:47.70% Validation Accuracy:48.87%\n",
            "Train Loss:1.9825 Validation Loss:1.9688\n",
            "\n",
            "\n",
            "Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:46<00:00, 33.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 10\n",
            "Train Accuracy:48.03% Validation Accuracy:50.03%\n",
            "Train Loss:1.9761 Validation Loss:1.9570\n",
            "\n",
            "\n",
            "Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 11\n",
            "Train Accuracy:49.47% Validation Accuracy:51.34%\n",
            "Train Loss:1.9647 Validation Loss:1.9463\n",
            "\n",
            "\n",
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 12\n",
            "Train Accuracy:49.42% Validation Accuracy:50.60%\n",
            "Train Loss:1.9636 Validation Loss:1.9526\n",
            "\n",
            "\n",
            "Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 13\n",
            "Train Accuracy:52.13% Validation Accuracy:54.44%\n",
            "Train Loss:1.9381 Validation Loss:1.9154\n",
            "\n",
            "\n",
            "Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 14\n",
            "Train Accuracy:53.34% Validation Accuracy:55.74%\n",
            "Train Loss:1.9264 Validation Loss:1.9035\n",
            "\n",
            "\n",
            "Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 15\n",
            "Train Accuracy:53.81% Validation Accuracy:55.80%\n",
            "Train Loss:1.9212 Validation Loss:1.9003\n",
            "\n",
            "\n",
            "Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 16\n",
            "Train Accuracy:53.59% Validation Accuracy:55.78%\n",
            "Train Loss:1.9234 Validation Loss:1.9008\n",
            "\n",
            "\n",
            "Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 17\n",
            "Train Accuracy:56.59% Validation Accuracy:58.29%\n",
            "Train Loss:1.8954 Validation Loss:1.8777\n",
            "\n",
            "\n",
            "Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:46<00:00, 33.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 18\n",
            "Train Accuracy:57.00% Validation Accuracy:58.81%\n",
            "Train Loss:1.8903 Validation Loss:1.8713\n",
            "\n",
            "\n",
            "Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:46<00:00, 33.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19\n",
            "Train Accuracy:57.53% Validation Accuracy:59.34%\n",
            "Train Loss:1.8851 Validation Loss:1.8652\n",
            "\n",
            "\n",
            "Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 20\n",
            "Train Accuracy:58.66% Validation Accuracy:60.09%\n",
            "Train Loss:1.8744 Validation Loss:1.8594\n",
            "\n",
            "\n",
            "Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 21\n",
            "Train Accuracy:58.88% Validation Accuracy:60.77%\n",
            "Train Loss:1.8706 Validation Loss:1.8547\n",
            "\n",
            "\n",
            "Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 22\n",
            "Train Accuracy:58.13% Validation Accuracy:59.54%\n",
            "Train Loss:1.8790 Validation Loss:1.8634\n",
            "\n",
            "\n",
            "Epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23\n",
            "Train Accuracy:60.65% Validation Accuracy:62.23%\n",
            "Train Loss:1.8545 Validation Loss:1.8370\n",
            "\n",
            "\n",
            "Epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24\n",
            "Train Accuracy:60.03% Validation Accuracy:62.13%\n",
            "Train Loss:1.8602 Validation Loss:1.8395\n",
            "\n",
            "\n",
            "Epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25\n",
            "Train Accuracy:61.83% Validation Accuracy:63.47%\n",
            "Train Loss:1.8437 Validation Loss:1.8277\n",
            "\n",
            "\n",
            "Epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 33.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 26\n",
            "Train Accuracy:61.88% Validation Accuracy:63.58%\n",
            "Train Loss:1.8425 Validation Loss:1.8246\n",
            "\n",
            "\n",
            "Epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27\n",
            "Train Accuracy:62.57% Validation Accuracy:63.91%\n",
            "Train Loss:1.8347 Validation Loss:1.8198\n",
            "\n",
            "\n",
            "Epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 28\n",
            "Train Accuracy:62.70% Validation Accuracy:64.12%\n",
            "Train Loss:1.8338 Validation Loss:1.8209\n",
            "\n",
            "\n",
            "Epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29\n",
            "Train Accuracy:63.39% Validation Accuracy:64.80%\n",
            "Train Loss:1.8271 Validation Loss:1.8122\n",
            "\n",
            "\n",
            "Epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 30\n",
            "Train Accuracy:63.49% Validation Accuracy:65.38%\n",
            "Train Loss:1.8257 Validation Loss:1.8091\n",
            "\n",
            "\n",
            "Epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 31\n",
            "Train Accuracy:64.72% Validation Accuracy:65.97%\n",
            "Train Loss:1.8154 Validation Loss:1.8017\n",
            "\n",
            "\n",
            "Epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 32\n",
            "Train Accuracy:65.44% Validation Accuracy:66.76%\n",
            "Train Loss:1.8078 Validation Loss:1.7937\n",
            "\n",
            "\n",
            "Epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 33\n",
            "Train Accuracy:65.07% Validation Accuracy:66.31%\n",
            "Train Loss:1.8108 Validation Loss:1.7980\n",
            "\n",
            "\n",
            "Epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 34\n",
            "Train Accuracy:65.02% Validation Accuracy:66.73%\n",
            "Train Loss:1.8108 Validation Loss:1.7961\n",
            "\n",
            "\n",
            "Epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 35\n",
            "Train Accuracy:66.47% Validation Accuracy:67.16%\n",
            "Train Loss:1.7961 Validation Loss:1.7884\n",
            "\n",
            "\n",
            "Epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 36\n",
            "Train Accuracy:67.09% Validation Accuracy:67.74%\n",
            "Train Loss:1.7907 Validation Loss:1.7821\n",
            "\n",
            "\n",
            "Epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 37\n",
            "Train Accuracy:66.93% Validation Accuracy:68.45%\n",
            "Train Loss:1.7925 Validation Loss:1.7790\n",
            "\n",
            "\n",
            "Epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 38\n",
            "Train Accuracy:67.90% Validation Accuracy:68.63%\n",
            "Train Loss:1.7826 Validation Loss:1.7727\n",
            "\n",
            "\n",
            "Epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 39\n",
            "Train Accuracy:67.81% Validation Accuracy:68.57%\n",
            "Train Loss:1.7829 Validation Loss:1.7740\n",
            "\n",
            "\n",
            "Epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 40\n",
            "Train Accuracy:68.53% Validation Accuracy:69.32%\n",
            "Train Loss:1.7765 Validation Loss:1.7676\n",
            "\n",
            "\n",
            "Epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 41\n",
            "Train Accuracy:68.60% Validation Accuracy:69.39%\n",
            "Train Loss:1.7751 Validation Loss:1.7666\n",
            "\n",
            "\n",
            "Epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 42\n",
            "Train Accuracy:68.94% Validation Accuracy:69.99%\n",
            "Train Loss:1.7727 Validation Loss:1.7612\n",
            "\n",
            "\n",
            "Epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 43\n",
            "Train Accuracy:68.97% Validation Accuracy:69.58%\n",
            "Train Loss:1.7711 Validation Loss:1.7656\n",
            "\n",
            "\n",
            "Epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 44\n",
            "Train Accuracy:69.89% Validation Accuracy:70.54%\n",
            "Train Loss:1.7633 Validation Loss:1.7580\n",
            "\n",
            "\n",
            "Epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 45\n",
            "Train Accuracy:69.99% Validation Accuracy:70.60%\n",
            "Train Loss:1.7622 Validation Loss:1.7566\n",
            "\n",
            "\n",
            "Epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 46\n",
            "Train Accuracy:70.39% Validation Accuracy:70.57%\n",
            "Train Loss:1.7576 Validation Loss:1.7525\n",
            "\n",
            "\n",
            "Epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 47\n",
            "Train Accuracy:70.88% Validation Accuracy:71.88%\n",
            "Train Loss:1.7530 Validation Loss:1.7457\n",
            "\n",
            "\n",
            "Epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 48\n",
            "Train Accuracy:71.14% Validation Accuracy:72.05%\n",
            "Train Loss:1.7512 Validation Loss:1.7428\n",
            "\n",
            "\n",
            "Epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 49\n",
            "Train Accuracy:71.13% Validation Accuracy:71.77%\n",
            "Train Loss:1.7514 Validation Loss:1.7459\n",
            "\n",
            "\n",
            "Epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 50\n",
            "Train Accuracy:72.38% Validation Accuracy:72.59%\n",
            "Train Loss:1.7383 Validation Loss:1.7355\n",
            "\n",
            "\n",
            "Epoch 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 51\n",
            "Train Accuracy:70.78% Validation Accuracy:70.93%\n",
            "Train Loss:1.7539 Validation Loss:1.7508\n",
            "\n",
            "\n",
            "Epoch 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 52\n",
            "Train Accuracy:71.38% Validation Accuracy:71.64%\n",
            "Train Loss:1.7484 Validation Loss:1.7447\n",
            "\n",
            "\n",
            "Epoch 52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 53\n",
            "Train Accuracy:72.79% Validation Accuracy:73.13%\n",
            "Train Loss:1.7352 Validation Loss:1.7306\n",
            "\n",
            "\n",
            "Epoch 53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 54\n",
            "Train Accuracy:72.34% Validation Accuracy:72.22%\n",
            "Train Loss:1.7384 Validation Loss:1.7371\n",
            "\n",
            "\n",
            "Epoch 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 55\n",
            "Train Accuracy:72.10% Validation Accuracy:72.48%\n",
            "Train Loss:1.7400 Validation Loss:1.7363\n",
            "\n",
            "\n",
            "Epoch 55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 56\n",
            "Train Accuracy:73.04% Validation Accuracy:72.91%\n",
            "Train Loss:1.7310 Validation Loss:1.7318\n",
            "\n",
            "\n",
            "Epoch 56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 57\n",
            "Train Accuracy:73.87% Validation Accuracy:73.89%\n",
            "Train Loss:1.7237 Validation Loss:1.7228\n",
            "\n",
            "\n",
            "Epoch 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 58\n",
            "Train Accuracy:72.28% Validation Accuracy:72.62%\n",
            "Train Loss:1.7378 Validation Loss:1.7339\n",
            "\n",
            "\n",
            "Epoch 58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 59\n",
            "Train Accuracy:73.60% Validation Accuracy:73.77%\n",
            "Train Loss:1.7256 Validation Loss:1.7229\n",
            "\n",
            "\n",
            "Epoch 59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 60\n",
            "Train Accuracy:74.42% Validation Accuracy:74.16%\n",
            "Train Loss:1.7180 Validation Loss:1.7180\n",
            "\n",
            "\n",
            "Epoch 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 61\n",
            "Train Accuracy:73.61% Validation Accuracy:73.57%\n",
            "Train Loss:1.7257 Validation Loss:1.7249\n",
            "\n",
            "\n",
            "Epoch 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 62\n",
            "Train Accuracy:74.65% Validation Accuracy:74.54%\n",
            "Train Loss:1.7157 Validation Loss:1.7169\n",
            "\n",
            "\n",
            "Epoch 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 63\n",
            "Train Accuracy:73.65% Validation Accuracy:74.00%\n",
            "Train Loss:1.7248 Validation Loss:1.7217\n",
            "\n",
            "\n",
            "Epoch 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 64\n",
            "Train Accuracy:74.44% Validation Accuracy:74.30%\n",
            "Train Loss:1.7169 Validation Loss:1.7184\n",
            "\n",
            "\n",
            "Epoch 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 65\n",
            "Train Accuracy:71.88% Validation Accuracy:71.84%\n",
            "Train Loss:1.7419 Validation Loss:1.7423\n",
            "\n",
            "\n",
            "Epoch 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 66\n",
            "Train Accuracy:75.42% Validation Accuracy:75.03%\n",
            "Train Loss:1.7078 Validation Loss:1.7105\n",
            "\n",
            "\n",
            "Epoch 66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 67\n",
            "Train Accuracy:74.07% Validation Accuracy:74.01%\n",
            "Train Loss:1.7211 Validation Loss:1.7211\n",
            "\n",
            "\n",
            "Epoch 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 68\n",
            "Train Accuracy:75.18% Validation Accuracy:74.71%\n",
            "Train Loss:1.7096 Validation Loss:1.7143\n",
            "\n",
            "\n",
            "Epoch 68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 69\n",
            "Train Accuracy:75.11% Validation Accuracy:74.80%\n",
            "Train Loss:1.7106 Validation Loss:1.7135\n",
            "\n",
            "\n",
            "Epoch 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 70\n",
            "Train Accuracy:75.33% Validation Accuracy:74.83%\n",
            "Train Loss:1.7083 Validation Loss:1.7118\n",
            "\n",
            "\n",
            "Epoch 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 34.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 71\n",
            "Train Accuracy:75.22% Validation Accuracy:75.27%\n",
            "Train Loss:1.7098 Validation Loss:1.7076\n",
            "\n",
            "\n",
            "Epoch 71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 72\n",
            "Train Accuracy:74.72% Validation Accuracy:75.05%\n",
            "Train Loss:1.7146 Validation Loss:1.7106\n",
            "\n",
            "\n",
            "Epoch 72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 73\n",
            "Train Accuracy:75.63% Validation Accuracy:75.75%\n",
            "Train Loss:1.7048 Validation Loss:1.7033\n",
            "\n",
            "\n",
            "Epoch 73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 74\n",
            "Train Accuracy:76.98% Validation Accuracy:76.44%\n",
            "Train Loss:1.6926 Validation Loss:1.6961\n",
            "\n",
            "\n",
            "Epoch 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 75\n",
            "Train Accuracy:76.04% Validation Accuracy:75.22%\n",
            "Train Loss:1.7019 Validation Loss:1.7072\n",
            "\n",
            "\n",
            "Epoch 75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 76\n",
            "Train Accuracy:76.74% Validation Accuracy:76.05%\n",
            "Train Loss:1.6950 Validation Loss:1.7006\n",
            "\n",
            "\n",
            "Epoch 76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 77\n",
            "Train Accuracy:76.73% Validation Accuracy:76.57%\n",
            "Train Loss:1.6935 Validation Loss:1.6958\n",
            "\n",
            "\n",
            "Epoch 77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 78\n",
            "Train Accuracy:77.33% Validation Accuracy:76.64%\n",
            "Train Loss:1.6886 Validation Loss:1.6945\n",
            "\n",
            "\n",
            "Epoch 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:45<00:00, 34.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 79\n",
            "Train Accuracy:76.17% Validation Accuracy:75.99%\n",
            "Train Loss:1.7000 Validation Loss:1.7006\n",
            "\n",
            "\n",
            "Epoch 79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [00:44<00:00, 35.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 80\n",
            "Train Accuracy:77.48% Validation Accuracy:77.20%\n",
            "Train Loss:1.6873 Validation Loss:1.6907\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def plot_accuracies(train_accuracies, test_accuracies):\n",
        "    plt.plot(train_accuracies, '-rx')\n",
        "    plt.plot(test_accuracies, '-bx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Accuracy vs. No. of epochs')\n",
        "\n",
        "    if quaternion:\n",
        "      with open('qnn', 'w') as f:\n",
        "          # create the csv writer\n",
        "          writer = csv.writer(f)\n",
        "\n",
        "          # write a row to the csv file\n",
        "          writer.writerow(test_accuracies)\n",
        "          writer.writerow(train_losses)\n",
        "    else:\n",
        "      with open('cnn', 'w') as f:\n",
        "          # create the csv writer\n",
        "          writer = csv.writer(f)\n",
        "\n",
        "          # write a row to the csv file\n",
        "          writer.writerow(test_accuracies)\n",
        "          writer.writerow(train_losses)\n",
        "\n",
        "plot_accuracies(train_accuracies, test_accuracies)"
      ],
      "metadata": {
        "id": "l55gqXT3ZVD1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0e1676e2-986d-47f4-aeac-b5c8844a912f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot results of the real-valued CNN"
      ],
      "metadata": {
        "id": "6Twh_ihzJQ0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(train_losses)\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "CBt-mY1uojv2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2dd52746-5b28-4f66-fdef-b1206a68ec8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}